import os
import random
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from tqdm import tqdm
import time

from siamese_model import SiameseNetwork

# ==========================================
# Configuration
# ==========================================
BATCH_SIZE = 32
EPOCHS = 10
LEARNING_RATE = 0.0005
MARGIN = 1.0  # Triplet Lossì˜ ë§ˆì§„ ê°’ (ê±°ë¦¬ë¥¼ ì–¼ë§ˆë‚˜ ë²Œë¦´ ê²ƒì¸ê°€)
DEVICE = "mps" if torch.backends.mps.is_available() else "cpu"


class TripletGTZANDataset(Dataset):
    """
    GTZAN ë°ì´í„°ì…‹ì—ì„œ Anchor, Positive, Negative ìŒì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    - Anchor: ëœë¤ ì´ë¯¸ì§€
    - Positive: Anchorì™€ ê°™ì€ ì¥ë¥´ì˜ ë‹¤ë¥¸ ì´ë¯¸ì§€
    - Negative: Anchorì™€ ë‹¤ë¥¸ ì¥ë¥´ì˜ ì´ë¯¸ì§€
    """

    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform

        # ì¥ë¥´ë³„ë¡œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì •ë¦¬
        # { 'blues': ['path/to/blues1.png', ...], 'jazz': [...] }
        self.data = {}
        self.genres = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]

        print("ğŸ“‚ Indexing Triplet Dataset...")
        for genre in self.genres:
            genre_dir = os.path.join(root_dir, genre)
            files = [os.path.join(genre_dir, f) for f in os.listdir(genre_dir) if f.endswith('.png')]
            if len(files) > 0:
                self.data[genre] = files

        # ì „ì²´ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ì¸ë±ì‹±ìš©)
        self.all_images = []
        for genre in self.genres:
            for img_path in self.data[genre]:
                self.all_images.append((img_path, genre))

    def __len__(self):
        return len(self.all_images)

    def __getitem__(self, index):
        # 1. Anchor ì„ íƒ
        anchor_path, anchor_genre = self.all_images[index]

        # 2. Positive ì„ íƒ (ê°™ì€ ì¥ë¥´, ë‹¤ë¥¸ íŒŒì¼)
        # ë¦¬ìŠ¤íŠ¸ì—ì„œ ìê¸° ìì‹ ì„ ì œì™¸í•˜ê³  ì„ íƒí•˜ë©´ ì¢‹ì§€ë§Œ,
        # ê°„ë‹¨í•˜ê²Œ ëœë¤ ì„ íƒ í›„ ê°™ìœ¼ë©´ ë‹¤ì‹œ ë½‘ëŠ” ë°©ì‹ ì‚¬ìš©
        pos_path = anchor_path
        while pos_path == anchor_path:
            pos_path = random.choice(self.data[anchor_genre])

        # 3. Negative ì„ íƒ (ë‹¤ë¥¸ ì¥ë¥´)
        neg_genre = anchor_genre
        while neg_genre == anchor_genre:
            neg_genre = random.choice(self.genres)
        neg_path = random.choice(self.data[neg_genre])

        # 4. ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
        anchor_img = Image.open(anchor_path).convert('RGB')
        pos_img = Image.open(pos_path).convert('RGB')
        neg_img = Image.open(neg_path).convert('RGB')

        if self.transform:
            anchor_img = self.transform(anchor_img)
            pos_img = self.transform(pos_img)
            neg_img = self.transform(neg_img)

        return anchor_img, pos_img, neg_img


def train_siamese():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    data_path = os.path.join(project_root, 'data', 'processed')
    save_path = os.path.join(project_root, 'models', 'siamese_net.pth')

    # 1. Dataset & DataLoader
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    dataset = TripletGTZANDataset(root_dir=data_path, transform=transform)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)  # Macì—ì„œëŠ” 0 ê¶Œì¥

    # 2. Model setup
    model = SiameseNetwork().to(DEVICE)

    # 3. Loss & Optimizer
    # TripletMarginLoss: max(d(a, p) - d(a, n) + margin, 0)
    criterion = nn.TripletMarginLoss(margin=MARGIN, p=2)

    # Optimizer: Head ë¶€ë¶„ë§Œ í•™ìŠµ (model.fc)
    optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)

    print(f"ğŸš€ Start Siamese Training on {DEVICE}")
    model.train()

    for epoch in range(EPOCHS):
        running_loss = 0.0
        pbar = tqdm(dataloader, desc=f"Epoch {epoch + 1}/{EPOCHS}")

        for anchor, positive, negative in pbar:
            anchor, positive, negative = anchor.to(DEVICE), positive.to(DEVICE), negative.to(DEVICE)

            optimizer.zero_grad()

            # Forward (3ê°œì˜ ì„ë² ë”© ì¶”ì¶œ)
            # forward í•¨ìˆ˜ê°€ (a, p, n)ì„ ë°›ì•„ 3ê°œë¥¼ ë¦¬í„´í•˜ë„ë¡ ìˆ˜ì •í–ˆìœ¼ë¯€ë¡œ í˜¸ì¶œ
            embed_a, embed_p, embed_n = model(anchor, positive, negative)

            # Loss ê³„ì‚°
            loss = criterion(embed_a, embed_p, embed_n)

            # Backward
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            pbar.set_postfix({'loss': loss.item()})

        epoch_loss = running_loss / len(dataloader)
        print(f"ğŸ“‰ Epoch {epoch + 1} Loss: {epoch_loss:.4f}")

        # ë§¤ ì—í¬í¬ë§ˆë‹¤ ì €ì¥
        torch.save(model.state_dict(), save_path)

    print(f"ğŸ‰ Training Complete! Model saved to {save_path}")


if __name__ == "__main__":
    train_siamese()