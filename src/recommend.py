import os
import torch
import numpy as np
import librosa
from torchvision import transforms
from PIL import Image
from tqdm import tqdm
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

# Siamese Model Import
from siamese_model import SiameseNetwork

# ==========================================
# Configuration
# ==========================================
DEVICE = "mps" if torch.backends.mps.is_available() else "cpu"
IMG_SIZE = 224


def load_siamese_model(model_path):
    """í•™ìŠµëœ ìƒ´ ë„¤íŠ¸ì›Œí¬ ë¡œë“œ"""
    print(f"ğŸ—ï¸ Loading Siamese Network from {os.path.basename(model_path)}...")
    model = SiameseNetwork().to(DEVICE)
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    else:
        print("âš ï¸ Warning: Model file not found. Recommendations will be random.")
    model.eval()
    return model


def audio_to_tensor(audio_path):
    """
    ì˜¤ë””ì˜¤(.wav) -> ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ -> í…ì„œ ë³€í™˜
    (Siamese Network ì…ë ¥ìš©)
    """
    try:
        # 1. Load Audio (3ì´ˆë§Œ ì‚¬ìš© - ëŒ€í‘œ êµ¬ê°„)
        y, sr = librosa.load(audio_path, sr=22050, duration=3.0)

        # ê¸¸ì´ê°€ ì§§ìœ¼ë©´ íŒ¨ë”©
        target_len = 22050 * 3
        if len(y) < target_len:
            y = np.pad(y, (0, target_len - len(y)))
        else:
            y = y[:target_len]

        # 2. Spectrogram
        mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
        log_mels = librosa.power_to_db(mels, ref=np.max)

        # 3. Save to Buffer (Matplotlib ì—†ì´ í”½ì…€ê°’ ë³€í™˜)
        # ì†ë„ë¥¼ ìœ„í•´ plt ëŒ€ì‹  min-max ì •ê·œí™”ë¡œ ì§ì ‘ ì´ë¯¸ì§€ ìƒì„±
        min_val = log_mels.min()
        max_val = log_mels.max()
        img_arr = (log_mels - min_val) / (max_val - min_val) * 255
        img_arr = img_arr.astype(np.uint8)

        # PIL Imageë¡œ ë³€í™˜ (Resizeë¥¼ ìœ„í•´)
        img = Image.fromarray(img_arr).convert('RGB')  # 3ì±„ë„ ë³µì‚¬

        # 4. Transform
        transform = transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        return transform(img).unsqueeze(0).to(DEVICE)

    except Exception as e:
        print(f"âŒ Error processing {audio_path}: {e}")
        return None


def build_database_index(model, data_dir):
    """
    ë°ì´í„°ì…‹ í´ë”(GTZAN ë“±)ë¥¼ ìŠ¤ìº”í•˜ì—¬ ëª¨ë“  ê³¡ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤.
    Returns: { 'filename': vector (numpy array) }
    """
    print("ğŸ“‚ Building Similarity Index (This may take a while)...")

    vectors = {}

    # data/processed í´ë”ê°€ ìˆë‹¤ë©´ ì´ë¯¸ì§€ë¥¼ ë°”ë¡œ ì”€ (ë¹ ë¦„)
    # ì—†ë‹¤ë©´ data/raw ì˜¤ë””ì˜¤ë¥¼ ë³€í™˜ (ëŠë¦¼)

    # ì—¬ê¸°ì„œëŠ” 'data/processed' (ì´ë¯¸ì§€)ê°€ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤ (preprocess.py ì‹¤í–‰ í›„)
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # ì¥ë¥´ í´ë” ìˆœíšŒ
    genres = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]

    for genre in tqdm(genres, desc="Indexing Genres"):
        genre_dir = os.path.join(data_dir, genre)
        files = [f for f in os.listdir(genre_dir) if f.endswith('.png')]

        # ë„ˆë¬´ ë§ìœ¼ë©´ ì¥ë¥´ë‹¹ 20ê°œë§Œ ìƒ˜í”Œë§ (ì†ë„ ìµœì í™” ë°ëª¨ìš©)
        # ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„  ë‹¤ í•´ì•¼ í•¨
        files = files[:20]

        for f in files:
            img_path = os.path.join(genre_dir, f)
            try:
                img = Image.open(img_path).convert('RGB')
                input_tensor = transform(img).unsqueeze(0).to(DEVICE)

                with torch.no_grad():
                    # Siamese Networkì˜ forward_one ì‚¬ìš©
                    emb = model.forward_one(input_tensor)
                    vectors[f"{genre}/{f}"] = emb.cpu().numpy().flatten()
            except:
                continue

    return vectors


def find_similar_songs(target_audio_path, model, db_vectors, top_k=5):
    """
    ì…ë ¥ëœ ì˜¤ë””ì˜¤ì™€ ê°€ì¥ ìœ ì‚¬í•œ ê³¡ Kê°œë¥¼ DBì—ì„œ ì°¾ìŠµë‹ˆë‹¤.
    """
    # 1. íƒ€ê²Ÿ ì˜¤ë””ì˜¤ ì„ë² ë”© ì¶”ì¶œ
    target_tensor = audio_to_tensor(target_audio_path)
    if target_tensor is None:
        return []

    with torch.no_grad():
        target_vec = model.forward_one(target_tensor).cpu().numpy().flatten()

    # 2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    db_keys = list(db_vectors.keys())
    db_vals = np.array(list(db_vectors.values()))

    target_vec = target_vec.reshape(1, -1)

    # (1, 128) vs (N, 128)
    sim_scores = cosine_similarity(target_vec, db_vals)[0]

    # 3. Top K ì¶”ì¶œ
    top_indices = sim_scores.argsort()[-top_k:][::-1]

    results = []
    for idx in top_indices:
        score = sim_scores[idx]
        name = db_keys[idx]
        # íŒŒì¼ëª… ì •ë¦¬ (blues/blues.00000_slice0.png -> blues.00000)
        clean_name = name.split('/')[-1].split('_slice')[0]
        results.append((clean_name, score))

    return results